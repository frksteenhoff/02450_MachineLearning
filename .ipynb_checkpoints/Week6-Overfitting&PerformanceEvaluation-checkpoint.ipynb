{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import *\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "from scipy.io import loadmat\n",
    "from sklearn import cross_validation, tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sklearn.linear_model as lm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Matlab data file and extract variables of interest\n",
    "mat_data = loadmat('Data/wine2.mat')\n",
    "X = np.matrix(mat_data['X'])\n",
    "y = np.matrix(mat_data['y'], dtype=int)\n",
    "attributeNames = [name[0] for name in mat_data['attributeNames'][0]]\n",
    "classNames = [name[0][0] for name in mat_data['classNames']]\n",
    "N, M = X.shape\n",
    "C = len(classNames)\n",
    "\n",
    "# Tree complexity parameter - constraint on maximum depth\n",
    "tc = np.arange(2, 21, 1)\n",
    "\n",
    "## Crossvalidation\n",
    "# Create crossvalidation partition for evaluation\n",
    "K = 10\n",
    "CV = cross_validation.KFold(N,K,shuffle=True)\n",
    "#CV = cross_validation.StratifiedKFold(y.A.ravel(),k=K)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# exercise 6.1.1\n",
    "# Simple holdout-set crossvalidation\n",
    "test_proportion = 0.5\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X,y,test_size=test_proportion)\n",
    "\n",
    "for i, t in enumerate(tc):\n",
    "    # Fit decision tree classifier, Gini split criterion, different pruning levels\n",
    "    dtc = tree.DecisionTreeClassifier(criterion='gini', max_depth=t)\n",
    "    dtc = dtc.fit(X_train,y_train.ravel().T)\n",
    "\n",
    "    # Evaluate classifier's misclassification rate over train/test data\n",
    "    y_est_test = dtc.predict(X_test)\n",
    "    y_est_train = dtc.predict(X_train)\n",
    "    misclass_rate_test = sum(np.abs(np.mat(y_est_test).T - y_test)) / float(len(y_est_test))\n",
    "    misclass_rate_train = sum(np.abs(np.mat(y_est_train).T - y_train)) / float(len(y_est_train))\n",
    "    Error_test[i], Error_train[i] = misclass_rate_test, misclass_rate_train\n",
    "    \n",
    "f = figure(); f.hold(True)\n",
    "plot(tc, Error_train)\n",
    "plot(tc, Error_test)\n",
    "xlabel('Model complexity (max tree depth)')\n",
    "ylabel('Error (misclassification rate)')\n",
    "legend(['Error_train','Error_test'])\n",
    "    \n",
    "show()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# exercise 6.1.2\n",
    "# Load Matlab data file and extract variables of interest\n",
    "# All from previous data\n",
    "\n",
    "# Initialize variable\n",
    "Error_train = np.empty((len(tc),K))\n",
    "Error_test = np.empty((len(tc),K))\n",
    "\n",
    "k=0\n",
    "for train_index, test_index in CV:\n",
    "    print('Computing CV fold: {0}/{1}..'.format(k+1,K))\n",
    "\n",
    "    # extract training and test set for current CV fold\n",
    "    X_train, y_train = X[train_index,:].A, y[train_index,:].A\n",
    "    X_test, y_test = X[test_index,:].A, y[test_index,:].A\n",
    "\n",
    "    for i, t in enumerate(tc):\n",
    "        # Fit decision tree classifier, Gini split criterion, different pruning levels\n",
    "        dtc = tree.DecisionTreeClassifier(criterion='gini', max_depth=t)\n",
    "        dtc = dtc.fit(X_train,y_train.ravel())\n",
    "        y_est_test = dtc.predict(X_test)\n",
    "        y_est_train = dtc.predict(X_train)\n",
    "        # Evaluate misclassification rate over train/test data (in this CV fold)\n",
    "        misclass_rate_test = sum(np.abs(np.mat(y_est_test).T - y_test)) / float(len(y_est_test))\n",
    "        misclass_rate_train = sum(np.abs(np.mat(y_est_train).T - y_train)) / float(len(y_est_train))\n",
    "        Error_test[i,k], Error_train[i,k] = misclass_rate_test, misclass_rate_train\n",
    "    k+=1\n",
    "\n",
    "    \n",
    "f = figure(); f.hold(True)\n",
    "boxplot(Error_test.T)\n",
    "xlabel('Model complexity (max tree depth)')\n",
    "ylabel('Test error across CV folds, K={0})'.format(K))\n",
    "\n",
    "f = figure(); f.hold(True)\n",
    "plot(tc, Error_train.mean(1))\n",
    "plot(tc, Error_test.mean(1))\n",
    "xlabel('Model complexity (max tree depth)')\n",
    "ylabel('Error (misclassification rate, CV K={0})'.format(K))\n",
    "legend(['Error_train','Error_test'])\n",
    "    \n",
    "show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# exercise 6.1.2\n",
    "# Load Matlab data file and extract variables of interest\n",
    "# All from previous data\n",
    "\n",
    "# Initialize variable\n",
    "Error_train = np.empty((len(tc),K))\n",
    "Error_test = np.empty((len(tc),K))\n",
    "\n",
    "k=0\n",
    "for train_index, test_index in CV:\n",
    "    print('Computing CV fold: {0}/{1}..'.format(k+1,K))\n",
    "\n",
    "    # extract training and test set for current CV fold\n",
    "    X_train, y_train = X[train_index,:].A, y[train_index,:].A\n",
    "    X_test, y_test = X[test_index,:].A, y[test_index,:].A\n",
    "\n",
    "    for i, t in enumerate(tc):\n",
    "        # Fit decision tree classifier, Gini split criterion, different pruning levels\n",
    "        dtc = tree.DecisionTreeClassifier(criterion='gini', max_depth=t)\n",
    "        dtc = dtc.fit(X_train,y_train.ravel())\n",
    "        y_est_test = dtc.predict(X_test)\n",
    "        y_est_train = dtc.predict(X_train)\n",
    "        # Evaluate misclassification rate over train/test data (in this CV fold)\n",
    "        misclass_rate_test = sum(np.abs(np.mat(y_est_test).T - y_test)) / float(len(y_est_test))\n",
    "        misclass_rate_train = sum(np.abs(np.mat(y_est_train).T - y_train)) / float(len(y_est_train))\n",
    "        Error_test[i,k], Error_train[i,k] = misclass_rate_test, misclass_rate_train\n",
    "    k+=1\n",
    "\n",
    "    \n",
    "f = figure(); f.hold(True)\n",
    "boxplot(Error_test.T)\n",
    "xlabel('Model complexity (max tree depth)')\n",
    "ylabel('Test error across CV folds, K={0})'.format(K))\n",
    "\n",
    "f = figure(); f.hold(True)\n",
    "plot(tc, Error_train.mean(1))\n",
    "plot(tc, Error_test.mean(1))\n",
    "xlabel('Model complexity (max tree depth)')\n",
    "ylabel('Error (misclassification rate, CV K={0})'.format(K))\n",
    "legend(['Error_train','Error_test'])\n",
    "    \n",
    "show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# exercise 6.3.1\n",
    "# Load Matlab data file and extract variables of interest\n",
    "# All from previous exercises\n",
    "\n",
    "# Initialize variables\n",
    "Error_logreg = np.empty((K,1))\n",
    "Error_dectree = np.empty((K,1))\n",
    "n_tested=0\n",
    "\n",
    "k=0\n",
    "for train_index, test_index in CV:\n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train = X[train_index,:]\n",
    "    y_train = y[train_index,:]\n",
    "    X_test = X[test_index,:]\n",
    "    y_test = y[test_index,:]\n",
    "\n",
    "    # Fit and evaluate Logistic Regression classifier\n",
    "    model = lm.logistic.LogisticRegression(C=N)\n",
    "    model = model.fit(X_train, y_train.A.ravel())\n",
    "    y_logreg = np.mat(model.predict(X_test)).T\n",
    "    Error_logreg[k] = 100*(y_logreg!=y_test).sum().astype(float)/len(y_test)\n",
    "    \n",
    "    # Fit and evaluate Decision Tree classifier\n",
    "    model2 = tree.DecisionTreeClassifier()\n",
    "    model2 = model2.fit(X_train, y_train.A.ravel())\n",
    "    y_dectree = np.mat(model2.predict(X_test)).T\n",
    "    Error_dectree[k] = 100*(y_dectree!=y_test).sum().astype(float)/len(y_test)\n",
    "\n",
    "    k+=1\n",
    "\n",
    "# Use T-test to check if classifiers are significantly different\n",
    "[tstatistic, pvalue] = stats.ttest_ind(Error_logreg,Error_dectree)\n",
    "if pvalue<=0.05:\n",
    "    print('Classifiers are significantly different. (p={0})'.format(pvalue[0]))\n",
    "else:\n",
    "    print('Classifiers are not significantly different (p={0})'.format(pvalue[0]))        \n",
    "    \n",
    "# Boxplot to compare classifier error distributions\n",
    "figure()\n",
    "boxplot(np.bmat('Error_logreg, Error_dectree'))\n",
    "xlabel('Logistic Regression   vs.   Decision Tree')\n",
    "ylabel('Cross-validation error [%]')\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
